{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7db3ea1-2fc8-4dd4-bb8c-c83d9840d3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Physics-Informed Neural Network for Biharmonic Problem (P4)\n",
      "Cahn-Hilliard Boundary Conditions - FINAL CORRECTED PyTorch Implementation\n",
      "Domain: Ω = (0,1)²\n",
      "Architecture: 4 hidden layers with 84 units each\n",
      "Training points: 20,000 interior, 6,000 boundary\n",
      "================================================================================\n",
      "================================================================================\n",
      "RUNNING EXAMPLE 1: u = (1/(2π²)) sin(πx) sin(πy)\n",
      "================================================================================\n",
      "Starting training for Example 1...\n",
      "Epoch     0: Total Loss = 5.90e+02, Int Loss = 9.75e+01, BC Loss = 4.92e+00, L2 Error = 1.70e-02, Energy Error = 1.31e-01\n",
      "Epoch   100: Total Loss = 5.44e+01, Int Loss = 2.27e+01, BC Loss = 3.16e-01, L2 Error = 3.86e-01, Energy Error = 5.07e-01\n",
      "Epoch   200: Total Loss = 2.06e+01, Int Loss = 8.72e+00, BC Loss = 1.18e-01, L2 Error = 2.57e-01, Energy Error = 3.15e-01\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create directory for saving plots and models\n",
    "os.makedirs('pinn_biharmonic_results_pytorch_final', exist_ok=True)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# =============================================================================\n",
    "# COMMON FUNCTIONS AND CLASSES\n",
    "# =============================================================================\n",
    "\n",
    "class BiharmonicPINN(nn.Module):\n",
    "    # --- CORRECTED: Changed Tanh to SiLU for better gradient flow ---\n",
    "    def __init__(self, layers, activation=nn.SiLU()):\n",
    "    # --- END CORRECTION ---\n",
    "        super(BiharmonicPINN, self).__init__()\n",
    "        self.layers = layers\n",
    "        self.activation = activation\n",
    "        \n",
    "        # Build neural network\n",
    "        self.linears = nn.ModuleList()\n",
    "        for i in range(len(layers)-1):\n",
    "            self.linears.append(nn.Linear(layers[i], layers[i+1]))\n",
    "            \n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        for linear in self.linears:\n",
    "            nn.init.xavier_normal_(linear.weight)\n",
    "            nn.init.constant_(linear.bias, 0.0)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        for i, linear in enumerate(self.linears):\n",
    "            x = linear(x)\n",
    "            if i < len(self.linears) - 1:  # No activation on output layer\n",
    "                x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "def compute_derivatives(u, x, y):\n",
    "    \"\"\"Compute all required derivatives using automatic differentiation\"\"\"\n",
    "    # First derivatives\n",
    "    u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), \n",
    "                             create_graph=True, retain_graph=True)[0]\n",
    "    u_y = torch.autograd.grad(u, y, grad_outputs=torch.ones_like(u), \n",
    "                             create_graph=True, retain_graph=True)[0]\n",
    "    \n",
    "    # Second derivatives\n",
    "    u_xx = torch.autograd.grad(u_x, x, grad_outputs=torch.ones_like(u_x), \n",
    "                              create_graph=True, retain_graph=True)[0]\n",
    "    u_yy = torch.autograd.grad(u_y, y, grad_outputs=torch.ones_like(u_y), \n",
    "                              create_graph=True, retain_graph=True)[0]\n",
    "    u_xy = torch.autograd.grad(u_x, y, grad_outputs=torch.ones_like(u_x), \n",
    "                              create_graph=True, retain_graph=True)[0]\n",
    "    \n",
    "    # Third derivatives\n",
    "    u_xxx = torch.autograd.grad(u_xx, x, grad_outputs=torch.ones_like(u_xx), \n",
    "                               create_graph=True, retain_graph=True)[0]\n",
    "    u_xxy = torch.autograd.grad(u_xx, y, grad_outputs=torch.ones_like(u_xx), \n",
    "                               create_graph=True, retain_graph=True)[0]\n",
    "    u_xyy = torch.autograd.grad(u_xy, y, grad_outputs=torch.ones_like(u_xy), \n",
    "                               create_graph=True, retain_graph=True)[0]\n",
    "    u_yyy = torch.autograd.grad(u_yy, y, grad_outputs=torch.ones_like(u_yy), \n",
    "                               create_graph=True, retain_graph=True)[0]\n",
    "    \n",
    "    # Fourth derivatives\n",
    "    u_xxxx = torch.autograd.grad(u_xxx, x, grad_outputs=torch.ones_like(u_xxx), \n",
    "                                create_graph=True, retain_graph=True)[0]\n",
    "    u_xxyy = torch.autograd.grad(u_xxy, y, grad_outputs=torch.ones_like(u_xxy), \n",
    "                                create_graph=True, retain_graph=True)[0]\n",
    "    u_yyyy = torch.autograd.grad(u_yyy, y, grad_outputs=torch.ones_like(u_yyy), \n",
    "                                create_graph=True, retain_graph=True)[0]\n",
    "    \n",
    "    return u, u_x, u_y, u_xx, u_yy, u_xy, u_xxx, u_xxy, u_xyy, u_yyy, u_xxxx, u_xxyy, u_yyyy\n",
    "\n",
    "def get_unit_normal(x, y):\n",
    "    \"\"\"Compute correct unit outward normal vectors for the unit square (0,1)^2\"\"\"\n",
    "    n_x = torch.zeros_like(x)\n",
    "    n_y = torch.zeros_like(y)\n",
    "    \n",
    "    # Left boundary (x=0): normal = (-1, 0)\n",
    "    left_mask = (x <= 1e-6)\n",
    "    n_x[left_mask] = -1.0\n",
    "    \n",
    "    # Right boundary (x=1): normal = (1, 0)\n",
    "    right_mask = (x >= 1.0 - 1e-6)\n",
    "    n_x[right_mask] = 1.0\n",
    "    \n",
    "    # Bottom boundary (y=0): normal = (0, -1)\n",
    "    bottom_mask = (y <= 1e-6)\n",
    "    n_y[bottom_mask] = -1.0\n",
    "    \n",
    "    # Top boundary (y=1): normal = (0, 1)\n",
    "    top_mask = (y >= 1.0 - 1e-6)\n",
    "    n_y[top_mask] = 1.0\n",
    "    \n",
    "    return n_x, n_y\n",
    "\n",
    "def compute_normal_derivatives(x, y, u_x, u_y, u_xx, u_yy, u_xy, u_xxx, u_xxy, u_xyy, u_yyy):\n",
    "    \"\"\"Compute normal derivatives and normal derivative of Laplacian\"\"\"\n",
    "    # Use correct unit normal vectors\n",
    "    n_x, n_y = get_unit_normal(x, y)\n",
    "    \n",
    "    # First normal derivative\n",
    "    u_n = n_x * u_x + n_y * u_y\n",
    "    \n",
    "    # Normal derivative of Laplacian\n",
    "    laplacian_x = u_xxx + u_xyy  # ∂/∂x(Δu)\n",
    "    laplacian_y = u_xxy + u_yyy  # ∂/∂y(Δu)\n",
    "    laplacian_n = n_x * laplacian_x + n_y * laplacian_y\n",
    "    \n",
    "    return u_n, laplacian_n\n",
    "\n",
    "def compute_biharmonic(u_xxxx, u_xxyy, u_yyyy):\n",
    "    \"\"\"Compute biharmonic operator Δ²u = u_xxxx + 2u_xxyy + u_yyyy\"\"\"\n",
    "    return u_xxxx + 2.0 * u_xxyy + u_yyyy\n",
    "\n",
    "def compute_errors(u_pred, u_exact, x, y):\n",
    "    \"\"\"Compute L2 and energy errors according to PDF definition\"\"\"\n",
    "    # L2 error: ∥u - uθ∥L2(Ω)\n",
    "    l2_error = torch.sqrt(torch.mean((u_pred - u_exact)**2))\n",
    "    \n",
    "    # Compute gradients for energy error\n",
    "    u_pred_x = torch.autograd.grad(u_pred, x, grad_outputs=torch.ones_like(u_pred), \n",
    "                                  create_graph=True, retain_graph=True)[0]\n",
    "    u_pred_y = torch.autograd.grad(u_pred, y, grad_outputs=torch.ones_like(u_pred), \n",
    "                                  create_graph=True, retain_graph=True)[0]\n",
    "    u_exact_x = torch.autograd.grad(u_exact, x, grad_outputs=torch.ones_like(u_exact), \n",
    "                                  create_graph=True, retain_graph=True)[0]\n",
    "    u_exact_y = torch.autograd.grad(u_exact, y, grad_outputs=torch.ones_like(u_exact), \n",
    "                                  create_graph=True, retain_graph=True)[0]\n",
    "    \n",
    "    # Energy error = ∥u - uθ∥L2(Ω) + ∥∇(u - uθ)∥L2(Ω)\n",
    "    grad_diff_norm = torch.sqrt(torch.mean((u_pred_x - u_exact_x)**2 + (u_pred_y - u_exact_y)**2))\n",
    "    energy_error = l2_error + grad_diff_norm\n",
    "    \n",
    "    # Relative errors\n",
    "    l2_norm_exact = torch.sqrt(torch.mean(u_exact**2))\n",
    "    grad_norm_exact = torch.sqrt(torch.mean(u_exact_x**2 + u_exact_y**2))\n",
    "    energy_norm_exact = l2_norm_exact + grad_norm_exact\n",
    "    \n",
    "    l2_relative = l2_error / l2_norm_exact\n",
    "    energy_relative = energy_error / energy_norm_exact\n",
    "    \n",
    "    return l2_error, energy_error, l2_relative, energy_relative\n",
    "\n",
    "def compute_final_errors(pinn, exact_solution, num_test_points=1000):\n",
    "    \"\"\"Compute final errors without gradient issues\"\"\"\n",
    "    # Create new test points with gradients enabled\n",
    "    x_test = torch.rand((num_test_points, 1), dtype=torch.float32, requires_grad=True).to(device)\n",
    "    y_test = torch.rand((num_test_points, 1), dtype=torch.float32, requires_grad=True).to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    X_test = torch.cat([x_test, y_test], dim=1)\n",
    "    u_pred = pinn(X_test)\n",
    "    u_exact = exact_solution(x_test, y_test)\n",
    "    \n",
    "    # L2 error\n",
    "    l2_error = torch.sqrt(torch.mean((u_pred - u_exact)**2))\n",
    "    \n",
    "    # Compute gradients for energy error\n",
    "    u_pred_x = torch.autograd.grad(u_pred, x_test, grad_outputs=torch.ones_like(u_pred), \n",
    "                                  create_graph=False, retain_graph=True)[0]\n",
    "    u_pred_y = torch.autograd.grad(u_pred, y_test, grad_outputs=torch.ones_like(u_pred), \n",
    "                                  create_graph=False, retain_graph=True)[0]\n",
    "    u_exact_x = torch.autograd.grad(u_exact, x_test, grad_outputs=torch.ones_like(u_exact), \n",
    "                                  create_graph=False, retain_graph=True)[0]\n",
    "    u_exact_y = torch.autograd.grad(u_exact, y_test, grad_outputs=torch.ones_like(u_exact), \n",
    "                                  create_graph=False, retain_graph=True)[0]\n",
    "    \n",
    "    # Energy error = ∥u - uθ∥L2(Ω) + ∥∇(u - uθ)∥L2(Ω)\n",
    "    grad_diff_norm = torch.sqrt(torch.mean((u_pred_x - u_exact_x)**2 + (u_pred_y - u_exact_y)**2))\n",
    "    energy_error = l2_error + grad_diff_norm\n",
    "    \n",
    "    # Relative errors\n",
    "    l2_norm_exact = torch.sqrt(torch.mean(u_exact**2))\n",
    "    grad_norm_exact = torch.sqrt(torch.mean(u_exact_x**2 + u_exact_y**2))\n",
    "    energy_norm_exact = l2_norm_exact + grad_norm_exact\n",
    "    \n",
    "    l2_relative = l2_error / l2_norm_exact\n",
    "    energy_relative = energy_error / energy_norm_exact\n",
    "    \n",
    "    return (l2_error.item(), energy_error.item(), \n",
    "            l2_relative.item(), energy_relative.item())\n",
    "\n",
    "# =============================================================================\n",
    "# EXAMPLE 1: u = (1/(2π²)) sin(πx) sin(πy)\n",
    "# =============================================================================\n",
    "\n",
    "def run_example1():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"RUNNING EXAMPLE 1: u = (1/(2π²)) sin(πx) sin(πy)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Exact solution and derivatives\n",
    "    def exact_solution1(x, y):\n",
    "        return (1.0/(2.0*np.pi**2)) * torch.sin(np.pi*x) * torch.sin(np.pi*y)\n",
    "    \n",
    "    def source_term1(x, y):\n",
    "        # CORRECT: f = Δ²u = 2π² sin(πx) sin(πy)\n",
    "        return (2.0 * np.pi**2) * torch.sin(np.pi*x) * torch.sin(np.pi*y)\n",
    "    \n",
    "    # Generate training data\n",
    "    N_int = 20000\n",
    "    N_bc = 6000\n",
    "    \n",
    "    # Interior collocation points\n",
    "    x_int = torch.rand((N_int, 1), dtype=torch.float32, requires_grad=True).to(device)\n",
    "    y_int = torch.rand((N_int, 1), dtype=torch.float32, requires_grad=True).to(device)\n",
    "    \n",
    "    # Boundary collocation points\n",
    "    N_bc_side = N_bc // 4\n",
    "    \n",
    "    # Bottom boundary (y=0)\n",
    "    x_bc_bottom = torch.rand((N_bc_side, 1), dtype=torch.float32, requires_grad=True).to(device)\n",
    "    y_bc_bottom = torch.zeros_like(x_bc_bottom, requires_grad=True)\n",
    "    \n",
    "    # Top boundary (y=1)\n",
    "    x_bc_top = torch.rand((N_bc_side, 1), dtype=torch.float32, requires_grad=True).to(device)\n",
    "    y_bc_top = torch.ones_like(x_bc_top, requires_grad=True)\n",
    "    \n",
    "    # Left boundary (x=0)\n",
    "    x_bc_left = torch.zeros((N_bc_side, 1), dtype=torch.float32, requires_grad=True).to(device)\n",
    "    y_bc_left = torch.rand((N_bc_side, 1), dtype=torch.float32, requires_grad=True).to(device)\n",
    "    \n",
    "    # Right boundary (x=1)\n",
    "    x_bc_right = torch.ones((N_bc_side, 1), dtype=torch.float32, requires_grad=True).to(device)\n",
    "    y_bc_right = torch.rand((N_bc_side, 1), dtype=torch.float32, requires_grad=True).to(device)\n",
    "    \n",
    "    # Combine boundary points\n",
    "    x_bc = torch.cat([x_bc_bottom, x_bc_top, x_bc_left, x_bc_right], dim=0)\n",
    "    y_bc = torch.cat([y_bc_bottom, y_bc_top, y_bc_left, y_bc_right], dim=0)\n",
    "    \n",
    "    # Initialize model\n",
    "    layers = [2, 84, 84, 84, 84, 1]\n",
    "    pinn = BiharmonicPINN(layers).to(device)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.Adam(pinn.parameters(), lr=1e-3)\n",
    "    \n",
    "    # Training parameters\n",
    "    epochs = 10000\n",
    "    print_interval = 100\n",
    "    \n",
    "    # Loss history\n",
    "    loss_history = []\n",
    "    int_loss_history = []\n",
    "    bc_loss_history = []\n",
    "    l2_error_history = []\n",
    "    energy_error_history = []\n",
    "    \n",
    "    # Training loop\n",
    "    def train_step():\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Interior points forward pass\n",
    "        X_int = torch.cat([x_int, y_int], dim=1)\n",
    "        u_int = pinn(X_int)\n",
    "        \n",
    "        # Compute derivatives for interior points\n",
    "        derivatives_int = compute_derivatives(u_int, x_int, y_int)\n",
    "        u_int, u_x_int, u_y_int, u_xx_int, u_yy_int, u_xy_int, u_xxx_int, u_xxy_int, u_xyy_int, u_yyy_int, u_xxxx_int, u_xxyy_int, u_yyyy_int = derivatives_int\n",
    "        \n",
    "        # Biharmonic operator\n",
    "        biharmonic_int = compute_biharmonic(u_xxxx_int, u_xxyy_int, u_yyyy_int)\n",
    "        \n",
    "        # Source term\n",
    "        f_int = source_term1(x_int, y_int)\n",
    "        \n",
    "        # Interior loss\n",
    "        loss_int = torch.mean((biharmonic_int - f_int)**2)\n",
    "        \n",
    "        # Boundary points forward pass\n",
    "        X_bc = torch.cat([x_bc, y_bc], dim=1)\n",
    "        u_bc = pinn(X_bc)\n",
    "        \n",
    "        # Compute derivatives for boundary points\n",
    "        derivatives_bc = compute_derivatives(u_bc, x_bc, y_bc)\n",
    "        u_bc, u_x_bc, u_y_bc, u_xx_bc, u_yy_bc, u_xy_bc, u_xxx_bc, u_xxy_bc, u_xyy_bc, u_yyy_bc, _, _, _ = derivatives_bc\n",
    "        \n",
    "        # Compute normal derivatives for PINN prediction\n",
    "        u_n_bc, laplacian_n_bc = compute_normal_derivatives(\n",
    "            x_bc, y_bc, u_x_bc, u_y_bc, u_xx_bc, u_yy_bc, u_xy_bc, \n",
    "            u_xxx_bc, u_xxy_bc, u_xyy_bc, u_yyy_bc\n",
    "        )\n",
    "        \n",
    "        # Compute exact boundary conditions using autograd\n",
    "        u_exact_bc = exact_solution1(x_bc, y_bc)\n",
    "        \n",
    "        # Compute exact first derivatives\n",
    "        u_exact_x_bc = torch.autograd.grad(u_exact_bc, x_bc, grad_outputs=torch.ones_like(u_exact_bc), \n",
    "                                          create_graph=True, retain_graph=True)[0]\n",
    "        u_exact_y_bc = torch.autograd.grad(u_exact_bc, y_bc, grad_outputs=torch.ones_like(u_exact_bc), \n",
    "                                          create_graph=True, retain_graph=True)[0]\n",
    "        \n",
    "        # Compute exact normal derivative (g1)\n",
    "        n_x_bc, n_y_bc = get_unit_normal(x_bc, y_bc)\n",
    "        u_n_exact_bc = n_x_bc * u_exact_x_bc + n_y_bc * u_exact_y_bc\n",
    "        \n",
    "        # Compute exact Laplacian and its normal derivative (g2)\n",
    "        u_exact_xx_bc = torch.autograd.grad(u_exact_x_bc, x_bc, grad_outputs=torch.ones_like(u_exact_x_bc), \n",
    "                                           create_graph=True, retain_graph=True)[0]\n",
    "        u_exact_yy_bc = torch.autograd.grad(u_exact_y_bc, y_bc, grad_outputs=torch.ones_like(u_exact_y_bc), \n",
    "                                           create_graph=True, retain_graph=True)[0]\n",
    "        laplacian_exact_bc = u_exact_xx_bc + u_exact_yy_bc\n",
    "        \n",
    "        # Compute gradient of Laplacian\n",
    "        laplacian_x_exact = torch.autograd.grad(laplacian_exact_bc, x_bc, grad_outputs=torch.ones_like(laplacian_exact_bc), \n",
    "                                                create_graph=True, retain_graph=True)[0]\n",
    "        laplacian_y_exact = torch.autograd.grad(laplacian_exact_bc, y_bc, grad_outputs=torch.ones_like(laplacian_exact_bc), \n",
    "                                                create_graph=True, retain_graph=True)[0]\n",
    "        \n",
    "        # Compute exact normal derivative of Laplacian (g2)\n",
    "        laplacian_n_exact_bc = n_x_bc * laplacian_x_exact + n_y_bc * laplacian_y_exact\n",
    "        \n",
    "        # Boundary loss\n",
    "        loss_bc = torch.mean((u_n_bc - u_n_exact_bc)**2) + \\\n",
    "                  torch.mean((laplacian_n_bc - laplacian_n_exact_bc)**2)\n",
    "        \n",
    "        # --- CORRECTED: Added lambda weighting ---\n",
    "        lambda_int = 1.0\n",
    "        lambda_bc = 100.0  # Weighting to stabilize training\n",
    "        total_loss = (lambda_int * loss_int) + (lambda_bc * loss_bc)\n",
    "        # --- END CORRECTION ---\n",
    "        \n",
    "        # Backward pass\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        return total_loss, loss_int, loss_bc\n",
    "    \n",
    "    # Test points for error computation during training\n",
    "    x_test_train = torch.rand((1000, 1), dtype=torch.float32, requires_grad=True).to(device)\n",
    "    y_test_train = torch.rand((1000, 1), dtype=torch.float32, requires_grad=True).to(device)\n",
    "    \n",
    "    print(\"Starting training for Example 1...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs + 1):\n",
    "        total_loss, loss_int, loss_bc = train_step()\n",
    "        \n",
    "        if epoch % print_interval == 0:\n",
    "            # Compute errors\n",
    "            X_test = torch.cat([x_test_train, y_test_train], dim=1)\n",
    "            u_pred = pinn(X_test)\n",
    "            u_exact = exact_solution1(x_test_train, y_test_train)\n",
    "            \n",
    "            l2_error, energy_error, l2_relative, energy_relative = compute_errors(\n",
    "                u_pred, u_exact, x_test_train, y_test_train\n",
    "            )\n",
    "            \n",
    "            loss_history.append(total_loss.item())\n",
    "            int_loss_history.append(loss_int.item())\n",
    "            bc_loss_history.append(loss_bc.item())\n",
    "            l2_error_history.append(l2_error.item())\n",
    "            energy_error_history.append(energy_error.item())\n",
    "            \n",
    "            print(f\"Epoch {epoch:5d}: Total Loss = {total_loss.item():.2e}, \"\n",
    "                  f\"Int Loss = {loss_int.item():.2e}, BC Loss = {loss_bc.item():.2e}, \"\n",
    "                  f\"L2 Error = {l2_error.item():.2e}, Energy Error = {energy_error.item():.2e}\")\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Training completed in {training_time:.2f} seconds\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PLOTTING AND SAVING RESULTS\n",
    "    # =========================================================================\n",
    "    \n",
    "    # Generate grid for final prediction\n",
    "    x_plot = np.linspace(0, 1, 100)\n",
    "    y_plot = np.linspace(0, 1, 100)\n",
    "    X_plot, Y_plot = np.meshgrid(x_plot, y_plot)\n",
    "    X_plot_flat = X_plot.flatten().reshape(-1, 1)\n",
    "    Y_plot_flat = Y_plot.flatten().reshape(-1, 1)\n",
    "    X_plot_tf = torch.tensor(np.hstack([X_plot_flat, Y_plot_flat]), dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Predictions\n",
    "    with torch.no_grad():\n",
    "        u_pred_plot = pinn(X_plot_tf).cpu().numpy().reshape(100, 100)\n",
    "    \n",
    "    u_exact_plot = exact_solution1(\n",
    "        torch.tensor(X_plot_flat, dtype=torch.float32).to(device), \n",
    "        torch.tensor(Y_plot_flat, dtype=torch.float32).to(device)\n",
    "    ).cpu().numpy().reshape(100, 100)\n",
    "    \n",
    "    error_plot = np.abs(u_pred_plot - u_exact_plot)\n",
    "    \n",
    "    # Plot 1: Loss history\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.semilogy(loss_history, label='Total Loss', linewidth=2)\n",
    "    plt.semilogy(int_loss_history, label='Interior Loss', linewidth=2)\n",
    "    plt.semilogy(bc_loss_history, label='Boundary Loss', linewidth=2)\n",
    "    plt.xlabel('Epoch (x100)')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Example 1: Training Loss History')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig('pinn_biharmonic_results_pytorch_final/example1_loss_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot 2: Error history\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.semilogy(l2_error_history, label='L2 Error', linewidth=2)\n",
    "    plt.semilogy(energy_error_history, label='Energy Error', linewidth=2)\n",
    "    plt.xlabel('Epoch (x100)')\n",
    "    plt.ylabel('Error')\n",
    "    plt.title('Example 1: Error History')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig('pinn_biharmonic_results_pytorch_final/example1_error_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot 3: Predicted solution\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    contour = plt.contourf(X_plot, Y_plot, u_pred_plot, levels=50, cmap='viridis')\n",
    "    plt.colorbar(contour)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title('Example 1: PINN Predicted Solution')\n",
    "    plt.savefig('pinn_biharmonic_results_pytorch_final/example1_predicted_solution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot 4: Exact solution\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    contour = plt.contourf(X_plot, Y_plot, u_exact_plot, levels=50, cmap='viridis')\n",
    "    plt.colorbar(contour)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title('Example 1: Exact Solution')\n",
    "    plt.savefig('pinn_biharmonic_results_pytorch_final/example1_exact_solution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot 5: Absolute error\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    contour = plt.contourf(X_plot, Y_plot, error_plot, levels=50, cmap='hot')\n",
    "    plt.colorbar(contour)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title('Example 1: Absolute Error')\n",
    "    plt.savefig('pinn_biharmonic_results_pytorch_final/example1_absolute_error.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 3D plots\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Predicted solution 3D\n",
    "    ax1 = fig.add_subplot(131, projection='3d')\n",
    "    surf1 = ax1.plot_surface(X_plot, Y_plot, u_pred_plot, cmap='viridis', alpha=0.8)\n",
    "    ax1.set_title('PINN Predicted Solution')\n",
    "    ax1.set_xlabel('x')\n",
    "    ax1.set_ylabel('y')\n",
    "    ax1.set_zlabel('u(x,y)')\n",
    "    \n",
    "    # Exact solution 3D\n",
    "    ax2 = fig.add_subplot(132, projection='3d')\n",
    "    surf2 = ax2.plot_surface(X_plot, Y_plot, u_exact_plot, cmap='viridis', alpha=0.8)\n",
    "    ax2.set_title('Exact Solution')\n",
    "    ax2.set_xlabel('x')\n",
    "    ax2.set_ylabel('y')\n",
    "    ax2.set_zlabel('u(x,y)')\n",
    "    \n",
    "    # Error 3D\n",
    "    ax3 = fig.add_subplot(133, projection='3d')\n",
    "    surf3 = ax3.plot_surface(X_plot, Y_plot, error_plot, cmap='hot', alpha=0.8)\n",
    "    ax3.set_title('Absolute Error')\n",
    "    ax3.set_xlabel('x')\n",
    "    ax3.set_ylabel('y')\n",
    "    ax3.set_zlabel('Error')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('pinn_biharmonic_results_pytorch_final/example1_3d_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Save model\n",
    "    torch.save({\n",
    "        'model_state_dict': pinn.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, 'pinn_biharmonic_results_pytorch_final/example1_model.pth')\n",
    "    \n",
    "    # Final error evaluation using the new function\n",
    "    print(\"Computing final errors...\")\n",
    "    l2_error_final, energy_error_final, l2_relative_final, energy_relative_final = compute_final_errors(\n",
    "        pinn, exact_solution1\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL RESULTS - EXAMPLE 1\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"L2 Error: {l2_error_final:.6e}\")\n",
    "    print(f\"Energy Error: {energy_error_final:.6e}\")\n",
    "    print(f\"Relative L2 Error: {l2_relative_final:.6e}\")\n",
    "    print(f\"Relative Energy Error: {energy_relative_final:.6e}\")\n",
    "    \n",
    "    return pinn\n",
    "\n",
    "# =============================================================================\n",
    "# EXAMPLE 2: u = x²y²(1-x)²(1-y)²\n",
    "# =============================================================================\n",
    "\n",
    "def run_example2():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RUNNING EXAMPLE 2: u = x²y²(1-x)²(1-y)²\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Exact solution\n",
    "    def exact_solution2(x, y):\n",
    "        return (x**2) * (y**2) * ((1-x)**2) * ((1-y)**2)\n",
    "    \n",
    "    # Generate training data\n",
    "    N_int = 20000\n",
    "    N_bc = 6000\n",
    "    \n",
    "    # Interior collocation points\n",
    "    x_int = torch.rand((N_int, 1), dtype=torch.float32, requires_grad=True).to(device)\n",
    "    y_int = torch.rand((N_int, 1), dtype=torch.float32, requires_grad=True).to(device)\n",
    "    \n",
    "    # Boundary collocation points\n",
    "    N_bc_side = N_bc // 4\n",
    "    \n",
    "    x_bc_bottom = torch.rand((N_bc_side, 1), dtype=torch.float32, requires_grad=True).to(device)\n",
    "    y_bc_bottom = torch.zeros_like(x_bc_bottom, requires_grad=True)\n",
    "    \n",
    "    x_bc_top = torch.rand((N_bc_side, 1), dtype=torch.float32, requires_grad=True).to(device)\n",
    "    y_bc_top = torch.ones_like(x_bc_top, requires_grad=True)\n",
    "    \n",
    "    x_bc_left = torch.zeros((N_bc_side, 1), dtype=torch.float32, requires_grad=True).to(device)\n",
    "    y_bc_left = torch.rand((N_bc_side, 1), dtype=torch.float32, requires_grad=True).to(device)\n",
    "    \n",
    "    x_bc_right = torch.ones((N_bc_side, 1), dtype=torch.float32, requires_grad=True).to(device)\n",
    "    y_bc_right = torch.rand((N_bc_side, 1), dtype=torch.float32, requires_grad=True).to(device)\n",
    "    \n",
    "    x_bc = torch.cat([x_bc_bottom, x_bc_top, x_bc_left, x_bc_right], dim=0)\n",
    "    y_bc = torch.cat([y_bc_bottom, y_bc_top, y_bc_left, y_bc_right], dim=0)\n",
    "    \n",
    "    # Initialize model\n",
    "    layers = [2, 84, 84, 84, 84, 1]\n",
    "    pinn = BiharmonicPINN(layers).to(device)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.Adam(pinn.parameters(), lr=1e-3)\n",
    "    \n",
    "    # Training parameters\n",
    "    epochs = 10000\n",
    "    print_interval = 100\n",
    "    \n",
    "    # Loss history\n",
    "    loss_history = []\n",
    "    int_loss_history = []\n",
    "    bc_loss_history = []\n",
    "    l2_error_history = []\n",
    "    energy_error_history = []\n",
    "    \n",
    "    # Training loop\n",
    "    def train_step():\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Interior points\n",
    "        X_int = torch.cat([x_int, y_int], dim=1)\n",
    "        u_int = pinn(X_int)\n",
    "        \n",
    "        derivatives_int = compute_derivatives(u_int, x_int, y_int)\n",
    "        u_int, u_x_int, u_y_int, u_xx_int, u_yy_int, u_xy_int, u_xxx_int, u_xxy_int, u_xyy_int, u_yyy_int, u_xxxx_int, u_xxyy_int, u_yyyy_int = derivatives_int\n",
    "        \n",
    "        biharmonic_int = compute_biharmonic(u_xxxx_int, u_xxyy_int, u_yyyy_int)\n",
    "        \n",
    "        # Compute source term using autograd on exact solution\n",
    "        u_exact_int = exact_solution2(x_int, y_int)\n",
    "        derivatives_exact_int = compute_derivatives(u_exact_int, x_int, y_int)\n",
    "        _, _, _, _, _, _, _, _, _, _, u_xxxx_exact, u_xxyy_exact, u_yyyy_exact = derivatives_exact_int\n",
    "        f_int = compute_biharmonic(u_xxxx_exact, u_xxyy_exact, u_yyyy_exact)\n",
    "        \n",
    "        loss_int = torch.mean((biharmonic_int - f_int)**2)\n",
    "        \n",
    "        # Boundary points\n",
    "        X_bc = torch.cat([x_bc, y_bc], dim=1)\n",
    "        u_bc = pinn(X_bc)\n",
    "        \n",
    "        derivatives_bc = compute_derivatives(u_bc, x_bc, y_bc)\n",
    "        u_bc, u_x_bc, u_y_bc, u_xx_bc, u_yy_bc, u_xy_bc, u_xxx_bc, u_xxy_bc, u_xyy_bc, u_yyy_bc, _, _, _ = derivatives_bc\n",
    "        \n",
    "        u_n_bc, laplacian_n_bc = compute_normal_derivatives(\n",
    "            x_bc, y_bc, u_x_bc, u_y_bc, u_xx_bc, u_yy_bc, u_xy_bc, \n",
    "            u_xxx_bc, u_xxy_bc, u_xyy_bc, u_yyy_bc\n",
    "        )\n",
    "        \n",
    "        # Compute exact boundary conditions using autograd\n",
    "        u_exact_bc = exact_solution2(x_bc, y_bc)\n",
    "        \n",
    "        # Compute exact first derivatives\n",
    "        u_exact_x_bc = torch.autograd.grad(u_exact_bc, x_bc, grad_outputs=torch.ones_like(u_exact_bc), \n",
    "                                          create_graph=True, retain_graph=True)[0]\n",
    "        u_exact_y_bc = torch.autograd.grad(u_exact_bc, y_bc, grad_outputs=torch.ones_like(u_exact_bc), \n",
    "                                          create_graph=True, retain_graph=True)[0]\n",
    "        \n",
    "        # Compute exact normal derivative (g1)\n",
    "        n_x_bc, n_y_bc = get_unit_normal(x_bc, y_bc)\n",
    "        u_n_exact_bc = n_x_bc * u_exact_x_bc + n_y_bc * u_exact_y_bc\n",
    "        \n",
    "        # Compute exact Laplacian and its normal derivative (g2)\n",
    "        u_exact_xx_bc = torch.autograd.grad(u_exact_x_bc, x_bc, grad_outputs=torch.ones_like(u_exact_x_bc), \n",
    "                                           create_graph=True, retain_graph=True)[0]\n",
    "        u_exact_yy_bc = torch.autograd.grad(u_exact_y_bc, y_bc, grad_outputs=torch.ones_like(u_exact_y_bc), \n",
    "                                           create_graph=True, retain_graph=True)[0]\n",
    "        laplacian_exact_bc = u_exact_xx_bc + u_exact_yy_bc\n",
    "        \n",
    "        # Compute gradient of Laplacian\n",
    "        laplacian_x_exact = torch.autograd.grad(laplacian_exact_bc, x_bc, grad_outputs=torch.ones_like(laplacian_exact_bc), \n",
    "                                                create_graph=True, retain_graph=True)[0]\n",
    "        laplacian_y_exact = torch.autograd.grad(laplacian_exact_bc, y_bc, grad_outputs=torch.ones_like(laplacian_exact_bc), \n",
    "                                                create_graph=True, retain_graph=True)[0]\n",
    "        \n",
    "        # Compute exact normal derivative of Laplacian (g2)\n",
    "        laplacian_n_exact_bc = n_x_bc * laplacian_x_exact + n_y_bc * laplacian_y_exact\n",
    "        \n",
    "        # Boundary loss\n",
    "        loss_bc = torch.mean((u_n_bc - u_n_exact_bc)**2) + \\\n",
    "                  torch.mean((laplacian_n_bc - laplacian_n_exact_bc)**2)\n",
    "        \n",
    "        # --- CORRECTED: Added lambda weighting ---\n",
    "        lambda_int = 1.0\n",
    "        lambda_bc = 100.0  # Weighting to stabilize training\n",
    "        total_loss = (lambda_int * loss_int) + (lambda_bc * loss_bc)\n",
    "        # --- END CORRECTION ---\n",
    "        \n",
    "        # Backward pass\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        return total_loss, loss_int, loss_bc\n",
    "    \n",
    "    # Test points for error computation during training\n",
    "    x_test_train = torch.rand((1000, 1), dtype=torch.float32, requires_grad=True).to(device)\n",
    "    y_test_train = torch.rand((1000, 1), dtype=torch.float32, requires_grad=True).to(device)\n",
    "    \n",
    "    print(\"Starting training for Example 2...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs + 1):\n",
    "        total_loss, loss_int, loss_bc = train_step()\n",
    "        \n",
    "        if epoch % print_interval == 0:\n",
    "            X_test = torch.cat([x_test_train, y_test_train], dim=1)\n",
    "            u_pred = pinn(X_test)\n",
    "            u_exact = exact_solution2(x_test_train, y_test_train)\n",
    "            \n",
    "            l2_error, energy_error, l2_relative, energy_relative = compute_errors(\n",
    "                u_pred, u_exact, x_test_train, y_test_train\n",
    "            )\n",
    "            \n",
    "            loss_history.append(total_loss.item())\n",
    "            int_loss_history.append(loss_int.item())\n",
    "            bc_loss_history.append(loss_bc.item())\n",
    "            l2_error_history.append(l2_error.item())\n",
    "            energy_error_history.append(energy_error.item())\n",
    "            \n",
    "            print(f\"Epoch {epoch:5d}: Total Loss = {total_loss.item():.2e}, \"\n",
    "                  f\"Int Loss = {loss_int.item():.2e}, BC Loss = {loss_bc.item():.2e}, \"\n",
    "                  f\"L2 Error = {l2_error.item():.2e}, Energy Error = {energy_error.item():.2e}\")\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Training completed in {training_time:.2f} seconds\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PLOTTING AND SAVING RESULTS\n",
    "    # =========================================================================\n",
    "    \n",
    "    # Generate grid for final prediction\n",
    "    x_plot = np.linspace(0, 1, 100)\n",
    "    y_plot = np.linspace(0, 1, 100)\n",
    "    X_plot, Y_plot = np.meshgrid(x_plot, y_plot)\n",
    "    X_plot_flat = X_plot.flatten().reshape(-1, 1)\n",
    "    Y_plot_flat = Y_plot.flatten().reshape(-1, 1)\n",
    "    X_plot_tf = torch.tensor(np.hstack([X_plot_flat, Y_plot_flat]), dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Predictions\n",
    "    with torch.no_grad():\n",
    "        u_pred_plot = pinn(X_plot_tf).cpu().numpy().reshape(100, 100)\n",
    "    \n",
    "    u_exact_plot = exact_solution2(\n",
    "        torch.tensor(X_plot_flat, dtype=torch.float32).to(device), \n",
    "        torch.tensor(Y_plot_flat, dtype=torch.float32).to(device)\n",
    "    ).cpu().numpy().reshape(100, 100)\n",
    "    \n",
    "    error_plot = np.abs(u_pred_plot - u_exact_plot)\n",
    "    \n",
    "    # Plot 1: Loss history\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.semilogy(loss_history, label='Total Loss', linewidth=2)\n",
    "    plt.semilogy(int_loss_history, label='Interior Loss', linewidth=2)\n",
    "    plt.semilogy(bc_loss_history, label='Boundary Loss', linewidth=2)\n",
    "    plt.xlabel('Epoch (x100)')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Example 2: Training Loss History')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig('pinn_biharmonic_results_pytorch_final/example2_loss_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot 2: Error history\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.semilogy(l2_error_history, label='L2 Error', linewidth=2)\n",
    "    plt.semilogy(energy_error_history, label='Energy Error', linewidth=2)\n",
    "    plt.xlabel('Epoch (x100)')\n",
    "    plt.ylabel('Error')\n",
    "    plt.title('Example 2: Error History')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig('pinn_biharmonic_results_pytorch_final/example2_error_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot 3: Predicted solution\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    contour = plt.contourf(X_plot, Y_plot, u_pred_plot, levels=50, cmap='viridis')\n",
    "    plt.colorbar(contour)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title('Example 2: PINN Predicted Solution')\n",
    "    plt.savefig('pinn_biharmonic_results_pytorch_final/example2_predicted_solution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot 4: Exact solution\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    contour = plt.contourf(X_plot, Y_plot, u_exact_plot, levels=50, cmap='viridis')\n",
    "    plt.colorbar(contour)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title('Example 2: Exact Solution')\n",
    "    plt.savefig('pinn_biharmonic_results_pytorch_final/example2_exact_solution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot 5: Absolute error\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    contour = plt.contourf(X_plot, Y_plot, error_plot, levels=50, cmap='hot')\n",
    "    plt.colorbar(contour)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title('Example 2: Absolute Error')\n",
    "    plt.savefig('pinn_biharmonic_results_pytorch_final/example2_absolute_error.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 3D plots\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    ax1 = fig.add_subplot(131, projection='3d')\n",
    "    surf1 = ax1.plot_surface(X_plot, Y_plot, u_pred_plot, cmap='viridis', alpha=0.8)\n",
    "    ax1.set_title('PINN Predicted Solution')\n",
    "    ax1.set_xlabel('x')\n",
    "    ax1.set_ylabel('y')\n",
    "    ax1.set_zlabel('u(x,y)')\n",
    "    \n",
    "    ax2 = fig.add_subplot(132, projection='3d')\n",
    "    surf2 = ax2.plot_surface(X_plot, Y_plot, u_exact_plot, cmap='viridis', alpha=0.8)\n",
    "    ax2.set_title('Exact Solution')\n",
    "    ax2.set_xlabel('x')\n",
    "    ax2.set_ylabel('y')\n",
    "    ax2.set_zlabel('u(x,y)')\n",
    "    \n",
    "    ax3 = fig.add_subplot(133, projection='3d')\n",
    "    surf3 = ax3.plot_surface(X_plot, Y_plot, error_plot, cmap='hot', alpha=0.8)\n",
    "    ax3.set_title('Absolute Error')\n",
    "    ax3.set_xlabel('x')\n",
    "    ax3.set_ylabel('y')\n",
    "    ax3.set_zlabel('Error')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('pinn_biharmonic_results_pytorch_final/example2_3d_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Save model\n",
    "    torch.save({\n",
    "        'model_state_dict': pinn.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, 'pinn_biharmonic_results_pytorch_final/example2_model.pth')\n",
    "    \n",
    "    # Final error evaluation using the new function\n",
    "    print(\"Computing final errors...\")\n",
    "    l2_error_final, energy_error_final, l2_relative_final, energy_relative_final = compute_final_errors(\n",
    "        pinn, exact_solution2\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL RESULTS - EXAMPLE 2\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"L2 Error: {l2_error_final:.6e}\")\n",
    "    print(f\"Energy Error: {energy_error_final:.6e}\")\n",
    "    print(f\"Relative L2 Error: {l2_relative_final:.6e}\")\n",
    "    print(f\"Relative Energy Error: {energy_relative_final:.6e}\")\n",
    "    \n",
    "    return pinn\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Physics-Informed Neural Network for Biharmonic Problem (P4)\")\n",
    "    print(\"Cahn-Hilliard Boundary Conditions - FINAL CORRECTED PyTorch Implementation\")\n",
    "    print(\"Domain: Ω = (0,1)²\")\n",
    "    print(\"Architecture: 4 hidden layers with 84 units each\")\n",
    "    print(\"Training points: 20,000 interior, 6,000 boundary\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Run both examples\n",
    "    pinn1 = run_example1()\n",
    "    pinn2 = run_example2()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ALL COMPUTATIONS COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"Results saved in 'pinn_biharmonic_results_pytorch_final' directory\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bba05f-d943-46cc-ada1-9fc886cb63cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
